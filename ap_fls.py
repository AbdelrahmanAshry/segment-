# -*- coding: utf-8 -*-
"""Ap Fls

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Um4-VX12Nu1T8wGBXiX9ZKDrG6w9LCOe

#APP
"""

import os
import torch
import torch.nn as nn
import numpy as np
from flask import Flask, request, redirect, url_for, render_template_string
from werkzeug.utils import secure_filename
from torchvision.models.segmentation import deeplabv3_resnet50,DeepLabV3_ResNet50_Weights
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import tifffile
#!pip install torchvision.models.segmentation

# Flask app setup
app = Flask(__name__)

# Define the path for uploads
UPLOAD_FOLDER = 'uploads/'
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

# Allowed file extensions for images and model weights
ALLOWED_EXTENSIONS = {'pth', 'png', 'jpg', 'jpeg', 'tif'}

# Create upload folder if it doesn't exist
if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

# Check if the file has a valid extension
def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# Load pre-trained model with modified input layer
def load_model(weights_path):
    try:

        model = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)
        if model is None:
         print ("Model failed to load.")
        model.backbone.conv1 = nn.Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        model.classifier[4] = nn.Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))

        # Load state_dict, ignoring keys related to aux_classifier
        state_dict = torch.load(weights_path, map_location=torch.device('cpu'), weights_only=True)
        # Filter out aux_classifier keys
        filtered_state_dict = {k: v for k, v in state_dict.items() if not k.startswith('aux_classifier')}
    
        model.load_state_dict(state_dict, strict=False)
        model.eval()  # Set the model to evaluation mode
    except Exception as e:
        raise RuntimeError(f"Error loading model: {e}")
    return model
# Preprocess image (multispectral 12-band) for model input
def preprocess_image(image_path, transform=None):
    try:
        # Load the 12-band .tif image using tifffile
        image = tifffile.imread(image_path).astype(np.float32)  # Shape [H, W, C] where C=12
        
        if image.shape[-1] != 12:
            raise ValueError("The image does not have 12 bands. Check the input image.")
        
        # Convert to tensor and permute to match PyTorch's expected [C, H, W] format
        image_tensor = transform['data'](image)
        return image_tensor

    except Exception as e:
        raise RuntimeError(f"Error preprocessing image: {e}")

# Visualization function for RGB image and predicted mask
def visualize_prediction(image_tensor, y_predicted_mask):
    try:
        # Convert image to numpy
        image_np = image_tensor.squeeze().cpu().numpy()
        rgb_image = np.stack([image_np[3], image_np[2], image_np[1]], axis=-1)  # Use bands [4, 3, 2]
        rgb_image = (rgb_image - rgb_image.min()) / (rgb_image.max() - rgb_image.min())  # Normalize for display

        # Get the predicted mask
        y_pred_mask_np = torch.sigmoid(y_predicted_mask).squeeze().cpu().detach().numpy()

        # Visualize RGB image and predicted mask
        fig, axs = plt.subplots(1, 2, figsize=(10, 5))
        axs[0].imshow(rgb_image)
        axs[0].set_title('RGB Image')
        axs[0].axis('off')

        axs[1].imshow(y_pred_mask_np, cmap='gray')
        axs[1].set_title('Predicted Mask')
        axs[1].axis('off')

        plt.show()
    except Exception as e:
        raise RuntimeError(f"Error in visualization: {e}")
data_transforms = {
    'data': transforms.Compose([
    transforms.ToTensor(),  # Convert to tensor
    transforms.Normalize(mean=[0.5]*12, std=[1]*12)  # Normalize the 12 channels
    ]),
    'mask': transforms.Compose([
    transforms.ToTensor(),  # Convert to tensor
    #transforms.Normalize(mean=[0.5]*1, std=[1]*1)  # Normalize the mask band
    ]),
}
# Route to upload weights and predict on an image
@app.route('/', methods=['GET', 'POST'])
def index():
    if request.method == 'POST':
        if 'weights' in request.files and 'image' in request.files:
            weights_file = request.files['weights']
            image_file = request.files['image']

            if allowed_file(weights_file.filename) and allowed_file(image_file.filename):
                # Save uploaded files
                weights_filename = secure_filename(weights_file.filename)
                image_filename = secure_filename(image_file.filename)
                UPLOAD_FOLDER = os.path.join(os.getcwd(), 'uploads')

                weights_path = os.path.join(app.config['UPLOAD_FOLDER'], weights_filename)
                image_path = os.path.join(app.config['UPLOAD_FOLDER'], image_filename)
 
                weights_file.save(weights_path)
                image_file.save(image_path)
                print(f"Saved weights to: {weights_path}")
                print(f"Saved image to: {image_path}")   
                try:
                    # Load model and predict

                    model = load_model(weights_path)
                    image_tensor = preprocess_image(image_path,data_transforms)
                    #image_tensor = image_tensor.repeat(8, 1, 1, 1)  # Shape now is [8, 12, 128, 128]

                    # Ensure tensor shape matches the model input
                    if image_tensor.shape != ( 12, 128, 128):
                        raise ValueError(f"Invalid image tensor shape: {image_tensor.shape}, expected (12, 128, 128)")

                    with torch.no_grad():
                        
                        y_pred_mask = model(image_tensor.unsqueeze(0))['out']#y_pred_mask = model(image_tensor)['out']#  shape 1,12,128,128                      y_pred_mask = model(image_tensor.unsqueeze(0))['out']
                        #output = model(image_tensor)
                        #if output is None or 'out' not in output:
                        #  raise RuntimeError("Model output is None or does not contain 'out'.")
                        #y_pred_mask = output['out']
                    # Visualize prediction
                    print("fShape image:(image_tensor.shape())")
                    print("fShape PRED mask:(y_pred_mask.shape())")
                    visualize_prediction(image_tensor, y_pred_mask)

                    return "Prediction complete! Check the terminal for the output."

                except Exception as e:
                    return f"Error during prediction: {e}"

    # Inline HTML form for file uploads
    html = '''
    <!DOCTYPE html>
    <html>
    <head><title>Upload Weights and Image</title></head>
    <body>
        <h1>Upload Weights and Image for Prediction</h1>
        <form method="POST" enctype="multipart/form-data">
            <label for="weights">Upload Model Weights (.pth):</label><br>
            <input type="file" name="weights"><br><br>
            <label for="image">Upload Image (12-band multispectral image .tif):</label><br>
            <input type="file" name="image"><br><br>
            <input type="submit" value="Upload and Predict">
        </form>
    </body>
    </html>
    '''
    return render_template_string(html)

if __name__ == '__main__':
    app.run(debug=True)
