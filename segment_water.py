# -*- coding: utf-8 -*-
"""bn1 water model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vZr-ex6YcwQlCIHNYygA6s3utEKdIthL
"""

import os
import torch
from torch.utils.data import DataLoader, random_split
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import Dataset
from PIL import Image
import tifffile as tiff
import numpy as np
import matplotlib.pyplot as plt
from torchvision.models import resnet34,ResNet34_Weights
from osgeo import gdal

""":LOAD data

"""

# Dataset class
class WaterSegmentationDataset(Dataset):
    def __init__(self, data_dir, labels_dir, transform=None):
        self.data_dir = data_dir
        self.labels_dir = labels_dir
        self.transform = transform
        self.data_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.tif')])
        self.label_files = sorted([os.path.join(labels_dir, f) for f in os.listdir(labels_dir) if f.endswith('.png')])

    def __len__(self):
        return len(self.data_files)

    def __getitem__(self, idx):
        # Load multispectral image (12-band)
        data_image = tiff.imread(self.data_files[idx]).astype(np.float32)  # Ensure it's float32

        # Load corresponding label image (binary mask)
        label_image = Image.open(self.label_files[idx])
        label_image = np.array(label_image)

        if self.transform:
            data_image = self.transform(data_image)

        label_image = torch.tensor(label_image, dtype=torch.long)  # Convert to tensor

        return data_image, label_image

# Define normalization transform
transform = transforms.Compose([
    transforms.ToTensor(),  # Convert to tensor
    transforms.Normalize(mean=[0.5]*12, std=[0.5]*12)  # Normalize the 12 channels
])

# Dataset loading
!ls "/content/drive/My Drive/datasets/data/images"
!ls "/content/drive/My Drive/datasets/data/labels"
data_dir = '/content/drive/My Drive/datasets/data/images'
labels_dir = '/content/drive/My Drive/datasets/data/labels'
dataset = WaterSegmentationDataset(data_dir, labels_dir, transform=transform)
# Split dataset into train, validation, and test sets (80/10/10)
train_size = int(0.8 * len(dataset))
valid_size = int(0.1 * len(dataset))
test_size = len(dataset) - train_size - valid_size

train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)

"""Pre Process Data and visualise"""

def visualize_sample(data_image, label_image):
    # Visualize three bands as an RGB approximation
    # Let's say bands 3, 2, 1 correspond to R, G, B channels
    rgb_image = data_image[:3].permute(1, 2, 0).numpy()  # Convert to HxWxC

    plt.figure(figsize=(10, 5))

    # Show RGB image
    plt.subplot(1, 2, 1)
    plt.imshow(rgb_image)
    plt.title('RGB Approximation')

    # Show label image
    plt.subplot(1, 2, 2)
    plt.imshow(label_image, cmap='gray')
    plt.title('Label (Binary Mask)')

    plt.show()
def load_and_visualize_multispectral_image(image_path, bands=[4, 3, 2]):
    # Load the image using GDAL
    dataset = gdal.Open(image_path)

    # Check the number of bands
    num_bands = dataset.RasterCount
    print(f"Number of bands: {num_bands}")

    # Select the specified bands (e.g., [4, 3, 2] for RGB)
    selected_bands = []
    for b in bands:
        band = dataset.GetRasterBand(b)
        selected_bands.append(band.ReadAsArray())

    # Stack the bands into an RGB image
    rgb_image = np.dstack(selected_bands)

    # Normalize the image for visualization (optional)
    rgb_image = (rgb_image - np.min(rgb_image)) / (np.max(rgb_image) - np.min(rgb_image))

    # Plot the image
    #plt.figure(figsize=(10, 10))
    plt.figure()
    plt.imshow(rgb_image)
    plt.title('RGB Image Visualization')
    plt.axis('off')
    plt.show()

# Visualize one sample

data_image, label_image = dataset[10]
visualize_sample(data_image, label_image)


# Visualize the first sample
load_and_visualize_multispectral_image('/content/drive/MyDrive/datasets/data/images/10.tif',bands=[4,3, 2])

"""MODEL used"""

class UNet(nn.Module):
    def __init__(self, num_classes):
        super(UNet, self).__init__()
        self.encoder = resnet34(weights=ResNet34_Weights)  # Pre-trained encoder (ResNet34)

        # Modify first conv layer to handle 12-band input
        self.encoder.conv1 = nn.Conv2d(12, 64, kernel_size=7, stride=2, padding=3, bias=False)

        # Define upsampling layers (decoder)
        self.upconv1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.upconv4 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)

        self.final_conv = nn.Conv2d(32, num_classes, kernel_size=1)

    def forward(self, x):
        # Encoder (using ResNet34)
        x1 = self.encoder.relu(self.encoder.bn1(self.encoder.conv1(x)))
        x1 = self.encoder.maxpool(x1)
        x2 = self.encoder.layer1(x1)
        x3 = self.encoder.layer2(x2)
        x4 = self.encoder.layer3(x3)
        x5 = self.encoder.layer4(x4)

        # Decoder (upsampling)
        x = self.upconv1(x5)
        x = self.upconv2(x + x4)
        x = self.upconv3(x + x3)
        x = self.upconv4(x + x2)

        x = self.final_conv(x)
        return x


# Instantiate model
model = UNet(num_classes=2)

# Move the model to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model=model.to(device)


# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for data_image, label_image in train_loader:
        data_image, label_image = data_image.to(device), label_image.to(device)

        optimizer.zero_grad()
        outputs = model(data_image)
        # Upsample the output to match the label size (128x128)
        outputs_upsampled = torch.nn.functional.interpolate(outputs, size=label_image.shape[1:], mode='bilinear', align_corners=False)

        loss = criterion(outputs_upsampled, label_image)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}")

    # Validate the model after each epoch
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for data_image, label_image in valid_loader:
            data_image, label_image = data_image.to(device), label_image.to(device)
            outputs = model(data_image)
            # Upsample the output to match the label size (128x128)
            outputs_upsample = torch.nn.functional.interpolate(outputs, size=label_image.shape[1:], mode='bilinear', align_corners=False)

            loss = criterion(outputs_upsample, label_image)
            val_loss += loss.item()
    print(f"Validation Loss after epoch {epoch+1}: {val_loss/len(valid_loader)}")

def visualize_multispectral_image_and_masks(image_tensor, y_predicted_mask, mask, bands=[4, 3, 2]):
    """
    Visualizes a multispectral image, predicted mask, and actual mask side by side.

    Args:
    - image_tensor (torch.Tensor): The input multispectral image (from dataloader, normalized).
    - y_predicted_mask (torch.Tensor): The predicted mask from the model.
    - mask (torch.Tensor): The ground truth mask from the dataloader.
    - bands (list): List of bands to select for RGB visualization, default is [4, 3, 2].
    """

    # Move image tensor and masks to CPU if necessary
    image_tensor = image_tensor.cpu()
    y_predicted_mask = y_predicted_mask.cpu()
    mask = mask.cpu()

    # Ensure the image has enough bands for the specified visualization
    assert image_tensor.shape[0] >= max(bands), f"Image does not have enough bands for {bands}"

    # Select the specified bands for RGB visualization (assuming normalization was done)
    image_np = image_tensor.numpy()
    rgb_image = np.stack([image_np[b - 1] for b in bands], axis=-1)  # Subtract 1 for zero indexing

    # Normalize the image for visualization
    rgb_image = (rgb_image - rgb_image.min()) / (rgb_image.max() - rgb_image.min())

    # Convert the predicted and actual masks to numpy for visualization
    y_predicted_mask = torch.argmax(y_predicted_mask, dim=0).numpy()  # Assuming multi-class output
    mask = mask.numpy()

    # Plot the RGB image, predicted mask, and ground truth mask
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))

    # Display the RGB image
    axs[0].imshow(rgb_image)
    axs[0].set_title('RGB Image')
    axs[0].axis('off')

    # Display the predicted mask
    axs[1].imshow(y_predicted_mask, cmap='gray')
    axs[1].set_title('Predicted Mask')
    axs[1].axis('off')

    # Display the ground truth mask
    axs[2].imshow(mask, cmap='gray')
    axs[2].set_title('Ground Truth Mask')
    axs[2].axis('off')

    plt.show()
data_test, label_test =  next(iter(test_loader))
y_predicted_mask =model(data_test)
predicted_upsampled = torch.nn.functional.interpolate(y_predicted_mask, size=label_image.shape[1:], mode='bilinear', align_corners=False)

num=2
visualize_multispectral_image_and_masks(data_test[num], predicted_upsampled[num], label_test[num])

"""#Evaluation"""

from sklearn.metrics import jaccard_score, precision_score, recall_score, f1_score


def evaluate_model(model, val_loader):
    model.eval()
    iou_scores, precision_scores, recall_scores, f1_scores = [], [], [], []

    with torch.no_grad():
        for images, masks in val_loader:
            images = images.to(device)
            outputs = model(images)
            # Upsample the output to match the mask size (128x128) before calculating the metrics
            outputs = torch.nn.functional.interpolate(outputs, size=masks.shape[1:], mode='bilinear', align_corners=False)

            predictions = torch.argmax(outputs, dim=1).cpu().numpy()

            masks = masks.cpu().numpy()

            iou_scores.append(jaccard_score(masks.flatten(), predictions.flatten(), average='binary'))
            precision_scores.append(precision_score(masks.flatten(), predictions.flatten(), average='binary'))
            recall_scores.append(recall_score(masks.flatten(), predictions.flatten(), average='binary'))
            f1_scores.append(f1_score(masks.flatten(), predictions.flatten(), average='binary'))

    print(f"IoU: {np.mean(iou_scores)}")
    print(f"Precision: {np.mean(precision_scores)}")
    print(f"Recall: {np.mean(recall_scores)}")
    print(f"F1-Score: {np.mean(f1_scores)}")

evaluate_model(model, test_loader)
